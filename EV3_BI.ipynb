{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65bd9763",
   "metadata": {},
   "source": [
    " ## Trabajo N.º 3 \n",
    "## Integración de árboles de decisión y clustering jerárquico en la modelación de patrones sísmicos en Chile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f7c254",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "Este trabajo integra y extiende los análisis realizados en las Evaluaciones 1 y 2 sobre la actividad sísmica en Chile, utilizando el mismo conjunto de datos de eventos registrados por el Centro Sismológico Nacional entre 2012 y 2025. El objetivo central es comparar el rendimiento e interpretabilidad de distintos modelos de regresión, incorporar árboles de decisión tanto regresivos como lógicos, y aplicar técnicas de clustering jerárquico para identificar patrones de agrupamiento en la magnitud, profundidad y localización de los sismos.\n",
    "\n",
    "A partir de las variables numéricas principales (Latitude, Longitude, Depth, Magnitude) y de la etiqueta derivada zona_sismica, se construyen y evalúan modelos de regresión lineal y basados en árboles, así como un árbol de decisión de clasificación y clústeres jerárquicos en variantes aditiva y divisiva. Los resultados permiten contrastar los modelos de las evaluaciones anteriores, visualizar reglas de decisión explícitas y descubrir grupos de eventos con comportamientos similares. Finalmente, se formulan conclusiones y recomendaciones de negocio orientadas a mejorar la interpretación de los patrones sísmicos y apoyar la priorización de zonas de vigilancia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c317e2",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "\n",
    "Chile es uno de los países con mayor actividad sísmica del mundo, lo que convierte a la medición, análisis y comunicación de los sismos en un problema permanente de seguridad y de gestión del riesgo. En las Evaluaciones 1 y 2 se trabajó con un conjunto de datos del Centro Sismológico Nacional, explorando la distribución de magnitudes y profundidades, comparando macrozonas y desarrollando modelos de regresión y clasificación básicos.\n",
    "\n",
    "En esta tercera entrega se retoma el mismo dataset, pero con un foco más integrado y reflexivo. Nuestro interés no es solo aplicar nuevas técnicas, sino también comparar lo realizado anteriormente y preguntarse qué modelos aportan mayor capacidad de explicación y apoyo a la toma de decisiones. Este trabajo busca profundizar la comprensión de cómo variables como latitud, longitud, profundidad y magnitud se relacionan entre sí, y cómo los modelos pueden ayudar a mejorar la detección de patrones relevantes para la gestión sísmica.\n",
    "\n",
    "La integración de árboles de decisión y clustering jerárquico permite avanzar hacia modelos más interpretables, donde las reglas y los agrupamientos puedan explicarse de manera sencilla a usuarios no técnicos, manteniendo al mismo tiempo una base cuantitativa sólida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d931611",
   "metadata": {},
   "source": [
    "## 3. Equipos, software y librerías utilizadas\n",
    "\n",
    "### 3.1 Equipo de trabajo\n",
    "\n",
    "El análisis se realizó en computadores con las siguientes características relevantes para el procesamiento de datos:\n",
    "\n",
    "- Procesador Intel Core i7\n",
    "- Memoria RAM 16 GB \n",
    "- Unidad de almacenamiento sólido (SSD) de 512 GB y 1 TB\n",
    "- Tarjetas de video: Intel UHD Graphics Xe (integrada) y NVIDIA GeForce RTX 3060\n",
    "- Sistema operativo Windows 10 de 64 bits.\n",
    "\n",
    "Estas especificaciones permiten trabajar de forma fluida con notebooks de Python, manejar dataframes de tamaño medio y ejecutar modelos de Machine Learning de complejidad moderada sin problemas de rendimiento.\n",
    "\n",
    "### 3.2 Software, entorno de desarrollo y trabajo colaborativo\n",
    "\n",
    "- Lenguaje: Python 3.12.10.\n",
    "- Entorno de desarrollo: Visual Studio Code con la extensión de Jupyter Notebook.\n",
    "- Sistema de control de versiones: Git y GitHub.\n",
    "- Cliente de escritorio: GitHub Desktop para sincronizar el repositorio entre distintos computadores de trabajo.\n",
    "- Estructura de carpetas:\n",
    "  - data/: contiene el archivo seismic_data.csv con los registros sísmicos.\n",
    "  - figuras/: almacena las imágenes generadas por los gráficos del análisis.\n",
    "\n",
    "El proyecto se gestionó mediante un repositorio en GitHub, utilizando GitHub Desktop para realizar commit, push y pull de los cambios entre equipos. Visual Studio Code se utilizó como editor principal para desarrollar el notebook, gestionar ramas cuando fue necesario y revisar el historial de versiones, lo que facilitó el trabajo colaborativo.\n",
    "\n",
    "### 3.3 Librerías principales\n",
    "\n",
    "Las librerías de Python más utilizadas en este trabajo son:\n",
    "\n",
    "- pandas y numpy para manipulación y preparación de datos.\n",
    "- matplotlib y seaborn para visualización de gráficos descriptivos y comparativos.\n",
    "- scikit-learn para construcción y evaluación de modelos de regresión, árboles de decisión, clasificación y clustering jerárquico.\n",
    "- nbformat e ipykernel como soporte para la ejecución reproducible del notebook.\n",
    "\n",
    "Las versiones específicas de estas dependencias se encuentran documentadas en el archivo requirements.txt del proyecto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e821bea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8a9d7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
