{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65bd9763",
   "metadata": {},
   "source": [
    " ## Trabajo N.º 3 \n",
    "## Integración de árboles de decisión y clustering jerárquico en la modelación de patrones sísmicos en Chile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f7c254",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "Este trabajo integra y extiende los análisis realizados en las Evaluaciones 1 y 2 sobre la actividad sísmica en Chile, utilizando el mismo conjunto de datos de eventos registrados por el Centro Sismológico Nacional entre 2012 y 2025. El objetivo central es comparar el rendimiento e interpretabilidad de distintos modelos de regresión, incorporar árboles de decisión tanto regresivos como lógicos, y aplicar técnicas de clustering jerárquico para identificar patrones de agrupamiento en la magnitud, profundidad y localización de los sismos.\n",
    "\n",
    "A partir de las variables numéricas principales (Latitude, Longitude, Depth, Magnitude) y de la etiqueta derivada zona_sismica, se construyen y evalúan modelos de regresión lineal y basados en árboles, así como un árbol de decisión de clasificación y clústeres jerárquicos en variantes aditiva y divisiva. Los resultados permiten contrastar los modelos de las evaluaciones anteriores, visualizar reglas de decisión explícitas y descubrir grupos de eventos con comportamientos similares. Finalmente, se formulan conclusiones y recomendaciones de negocio orientadas a mejorar la interpretación de los patrones sísmicos y apoyar la priorización de zonas de vigilancia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c317e2",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "\n",
    "Chile es uno de los países con mayor actividad sísmica del mundo, lo que convierte a la medición, análisis y comunicación de los sismos en un problema permanente de seguridad y de gestión del riesgo. En las Evaluaciones 1 y 2 se trabajó con un conjunto de datos del Centro Sismológico Nacional, explorando la distribución de magnitudes y profundidades, comparando macrozonas y desarrollando modelos de regresión y clasificación básicos.\n",
    "\n",
    "En esta tercera entrega se retoma el mismo dataset, pero con un foco más integrado y reflexivo. Nuestro interés no es solo aplicar nuevas técnicas, sino también comparar lo realizado anteriormente y preguntarse qué modelos aportan mayor capacidad de explicación y apoyo a la toma de decisiones. Este trabajo busca profundizar la comprensión de cómo variables como latitud, longitud, profundidad y magnitud se relacionan entre sí, y cómo los modelos pueden ayudar a mejorar la detección de patrones relevantes para la gestión sísmica.\n",
    "\n",
    "La integración de árboles de decisión y clustering jerárquico permite avanzar hacia modelos más interpretables, donde las reglas y los agrupamientos puedan explicarse de manera sencilla a usuarios no técnicos, manteniendo al mismo tiempo una base cuantitativa sólida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d931611",
   "metadata": {},
   "source": [
    "## 3. Equipos, software y librerías utilizadas\n",
    "\n",
    "### 3.1 Equipo de trabajo\n",
    "\n",
    "El análisis se realizó en computadores con las siguientes características relevantes para el procesamiento de datos:\n",
    "\n",
    "- Procesador Intel Core i7\n",
    "- Memoria RAM 16 GB \n",
    "- Unidad de almacenamiento sólido (SSD) de 512 GB y 1 TB\n",
    "- Tarjetas de video: Intel UHD Graphics Xe (integrada) y NVIDIA GeForce RTX 3060\n",
    "- Sistema operativo Windows 10 de 64 bits.\n",
    "\n",
    "Estas especificaciones permiten trabajar de forma fluida con notebooks de Python, manejar dataframes de tamaño medio y ejecutar modelos de Machine Learning de complejidad moderada sin problemas de rendimiento.\n",
    "\n",
    "### 3.2 Software, entorno de desarrollo y trabajo colaborativo\n",
    "\n",
    "- Lenguaje: Python 3.12.10.\n",
    "- Entorno de desarrollo: Visual Studio Code con la extensión de Jupyter Notebook.\n",
    "- Sistema de control de versiones: Git y GitHub.\n",
    "- Cliente de escritorio: GitHub Desktop para sincronizar el repositorio entre distintos computadores de trabajo.\n",
    "- Estructura de carpetas:\n",
    "  - data/: contiene el archivo seismic_data.csv con los registros sísmicos.\n",
    "  - figuras/: almacena las imágenes generadas por los gráficos del análisis.\n",
    "\n",
    "El proyecto se gestionó mediante un repositorio en GitHub, utilizando GitHub Desktop para realizar commit, push y pull de los cambios entre equipos. Visual Studio Code se utilizó como editor principal para desarrollar el notebook, gestionar ramas cuando fue necesario y revisar el historial de versiones, lo que facilitó el trabajo colaborativo.\n",
    "\n",
    "### 3.3 Librerías principales\n",
    "\n",
    "Las librerías de Python más utilizadas en este trabajo son:\n",
    "\n",
    "- pandas y numpy para manipulación y preparación de datos.\n",
    "- matplotlib y seaborn para visualización de gráficos descriptivos y comparativos.\n",
    "- scikit-learn para construcción y evaluación de modelos de regresión, árboles de decisión, clasificación y clustering jerárquico.\n",
    "- nbformat e ipykernel como soporte para la ejecución reproducible del notebook.\n",
    "\n",
    "Las versiones específicas de estas dependencias se encuentran documentadas en el archivo requirements.txt del proyecto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e821bea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2b2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. CONFIGURACIÓN GENERAL DEL PROYECTO\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Estilo de gráficos y opciones de Pandas\n",
    "plt.style.use(\"default\")\n",
    "sns.set(style=\"whitegrid\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.4f}\")\n",
    "\n",
    "# Directorios base\n",
    "DATA_DIR = \"data\"\n",
    "FIG_DIR = \"figuras\"\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "def guardar_figura(fig, nombre):\n",
    "    \"\"\"\n",
    "    Guarda una figura en la carpeta 'figuras' con nombre <nombre>.png\n",
    "    \"\"\"\n",
    "    ruta = os.path.join(FIG_DIR, f\"{nombre}.png\")\n",
    "    fig.savefig(ruta, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"Figura guardada en: {ruta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee7b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. CARGA DEL DATASET SÍSMICO\n",
    "# =============================================================================\n",
    "\n",
    "NOMBRE_ARCHIVO = \"seismic_data.csv\"\n",
    "ruta_csv = os.path.join(DATA_DIR, NOMBRE_ARCHIVO)\n",
    "\n",
    "if not os.path.exists(ruta_csv):\n",
    "    raise FileNotFoundError(\n",
    "        f\"No se encontró el archivo '{ruta_csv}'. \"\n",
    "        \"Verifique que el CSV esté dentro de la carpeta 'data/'.\"\n",
    "    )\n",
    "\n",
    "print(f\"Cargando dataset desde: {ruta_csv}\")\n",
    "df = pd.read_csv(ruta_csv)\n",
    "\n",
    "print(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594159ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6. PREPARACIÓN INICIAL DE VARIABLES\n",
    "# =============================================================================\n",
    "\n",
    "# Conversión de fecha a tipo datetime\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date(UTC)\"], errors=\"coerce\")\n",
    "\n",
    "df[\"Year\"] = df[\"Date\"].dt.year\n",
    "df[\"Month\"] = df[\"Date\"].dt.to_period(\"M\").astype(str)\n",
    "df[\"Day\"] = df[\"Date\"].dt.day\n",
    "\n",
    "def zona_por_lat(lat):\n",
    "    \"\"\"\n",
    "    Asigna una macrozona sísmica aproximada según la latitud:\n",
    "    - Norte: lat >= -23\n",
    "    - Centro: -38 <= lat < -23\n",
    "    - Sur: lat < -38\n",
    "    \"\"\"\n",
    "    if pd.isna(lat):\n",
    "        return np.nan\n",
    "    if lat >= -23:\n",
    "        return \"Norte\"\n",
    "    elif lat <= -38:\n",
    "        return \"Sur\"\n",
    "    else:\n",
    "        return \"Centro\"\n",
    "\n",
    "df[\"zona_sismica\"] = df[\"Latitude\"].apply(zona_por_lat)\n",
    "\n",
    "print(\"Distribución de la variable 'zona_sismica':\")\n",
    "print(df[\"zona_sismica\"].value_counts(dropna=False))\n",
    "display(df[[\"Date\", \"Latitude\", \"Longitude\", \"Depth\", \"Magnitude\", \"zona_sismica\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8a9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
